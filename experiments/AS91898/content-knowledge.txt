# AS91898 Content Knowledge File – Simplified for OMI Alignment

---

### 1. Metadata
- **Assessment Code and Title**: AS91898 – Demonstrate understanding of a computer science concept  
- **Level and Credits**: Level 2, 3 Credits  
- **Key Topics**: Artificial Intelligence, Core Mechanisms (Supervised Learning, CNN, LLM, Recommenders), Metrics, Data pipeline, Ethical Impacts, Real-world Applications (Social Media, Car Safety, Healthcare)  
- **Last Updated**: 2025-09-03  
- **Scaffolding Notes**:  
  - Simple = Achieved (name, describe)  
  - Detailed = Merit (explain, connect cause/effect)  
  - Implication = Excellence (evaluate, judge, propose fix)  
- **Source Files Used**: as91898.pdf, as91898.json, CS_Exam_AI_Resource.txt, 91898-cat-B-2023.pdf  

---

### 2. Key Terms

| Term | Definition |
|------|------------|
| Artificial Intelligence | Software that mimics human thinking to perform tasks. |
| Mechanism | A process or method that makes the system work. |
| Impact | A consequence of using the concept (ethical, social, human-factor, etc). |
| Machine Learning (ML) | A method where computers learn patterns from data. |
| Neural Network (NN) | A model that learns to recognise patterns in data. |
| Natural Language Processing (NLP) | AI that processes and generates human language. |
| Supervised Learning | ML using labelled data to learn patterns. |
| Accuracy | How often the model is correct overall. |
| Precision | How often positive results are correct. |
| Precision@K | Accuracy of the top-K recommendations. |
| Bias | Systematic unfairness in outcomes. |
| Privacy | Risks from collecting or storing sensitive data. |
| Explainability | How clearly we can understand AI’s decisions. |
| Misuse | Harmful or unintended use of AI. |
| Data Pipeline | Steps to collect, clean, split, and evaluate data. |
| Future-proofing | Designing AI to stay safe and relevant over time. |
| Chatbot | An AI system that interacts using natural language. |

---

### 3. Knowledge Tables (Simplified)

#### 3.1 Core AI Mechanisms

| Mechanism | Simple Sentence | Example | Main Risk |
|-----------|-----------------|---------|-----------|
| **Supervised Classification** | Learns from labelled examples to sort new data into the right group. | Social media filters hate speech; Car reads road signs. | Bias if training data is unbalanced. |
| **CNN (Convolutional Neural Network)** | Finds patterns in images so it can recognise objects. | Car detects pedestrians; Medical AI scans X-rays. | Can be hard to explain why it made a decision. |
| **Transformer / LLM (NLP)** | Predicts the next word to understand or create text. | Summarises doctor notes; Chatbot answers questions. | Can make up false information (hallucinations). |
| **Collaborative Recommender** | Suggests things liked by people with similar interests. | TikTok “For You” feed; Health app suggests workouts. | Can create echo chambers or spread misinformation. |

---

#### 3.2 Metrics and Evaluation

| Concept | Simple Sentence | Example | Risk |
|---------|-----------------|---------|------|
| Accuracy | How often the model is right. | CNN classifies 95/100 correctly. | Can hide false positives or negatives. |
| Precision | How often “yes” predictions are correct. | Spam filter flags 50 emails, 45 are spam. | High precision doesn’t mean it finds all spam. |
| Perplexity (NLP) | Lower = smoother, more accurate text predictions. | Low perplexity in health summaries sounds more natural. | Not used for images or recommenders. |
| Precision@K | Checks if the top-K suggestions are relevant. | 4 of top 5 TikTok videos match your interests. | Doesn’t measure long-term value or fairness. |

---

#### 3.3 Data Pipeline

| Stage | Simple Sentence | Example | Risk |
|-------|-----------------|---------|------|
| Collection | Gather examples for training. | Road camera footage; Medical reports. | Bad data = bad model. |
| Cleaning | Remove errors or sensitive details. | Blur faces in images; Anonymise patient info. | Leaks or bias if skipped. |
| Split | Keep test data separate from training data. | 80% train, 20% test for tumour detection. | Using test data in training fakes results. |
| Evaluation | Check performance using metrics. | 95% accuracy for skin-cancer detection. | One metric alone can mislead. |

---

#### 3.4 Ethical and Social Impacts

| Issue | Simple Sentence | Example | Risk |
|-------|-----------------|---------|------|
| Bias | AI can be unfair to some groups. | Filter flags cultural slang as hate speech. | Discrimination or harm. |
| Privacy | AI can expose sensitive data. | Health chatbot stores user answers. | Legal and ethical issues. |
| Explainability | Hard to see why AI made a decision. | CNN brakes without clear reason. | Loss of trust. |
| Misuse | AI used in harmful ways. | Deepfakes for scams. | Public trust erodes. |

---

### 4. Common Misconceptions / Errors

- Confusing accuracy with precision.  
- Naming a context without naming the mechanism.  
- Explaining what AI does without linking to how it works at a role level.  
- Mentioning an impact without cause/effect.  
- Talking about “future-proofing” without linking it to a risk.  
- Vague pros/cons not tied to examples.  

---

### 5. Applied Scenarios (Expanded)

---

#### 5.1 Healthcare

**ML (Supervised Classification)** – X-ray Classification  
- **Describe**: A supervised model classifies X-ray images as “healthy” or “tumour” using labelled examples.  
- **Explain**: Helps detect illness early **because** the AI spots patterns doctors might miss when busy.  
- **Discuss**: Risk of bias if training images mostly come from one age group. Fix by adding diverse examples.

**NN (CNN)** – Skin Cancer Detection  
- **Describe**: A CNN scans skin photos to detect early signs of melanoma.  
- **Explain**: Speeds up diagnosis **because** it can check thousands of images quickly.  
- **Discuss**: False positives may cause stress. Mitigate by having a doctor confirm results.

**NLP (LLM)** – Medical Note Summarisation  
- **Describe**: An LLM turns complex medical notes into patient-friendly summaries.  
- **Explain**: Saves time **because** patients can understand their care instructions.  
- **Discuss**: Hallucinations can add false info — require doctor review before sending to patients.

**ML (Supervised Classification)** – Early Disease Detection  
- **Describe**: AI analyses patient history and genetic data to predict risk of future illness.  
- **Explain**: Supports prevention **because** doctors can monitor at-risk patients earlier.  
- **Discuss**: Predictions may over-warn some groups — fix by combining AI with professional judgement.

**ML (Supervised / Regression)** – Personalized Treatment  
- **Describe**: AI analyses patient data to create tailored treatment plans.  
- **Explain**: Improves care **because** treatments match the patient’s unique needs.  
- **Discuss**: If training data excludes some groups, treatments may be less effective — fix by broadening datasets.

**ML (Drug Discovery)** – New Medicines  
- **Describe**: AI scans millions of molecules to suggest new drug candidates.  
- **Explain**: Speeds up discovery **because** it cuts down trial-and-error in labs.  
- **Discuss**: AI predictions may miss side effects — human testing still required.

**NLP + Admin Tools** – Healthcare Efficiency  
- **Describe**: AI automates admin tasks like appointment booking or billing.  
- **Explain**: Saves staff time **because** they can focus on patient care.  
- **Discuss**: Errors in scheduling could harm patients — fix with human oversight.

**Wearables + AI** – Remote Monitoring  
- **Describe**: AI analyses heart rate and activity data from wearables.  
- **Explain**: Supports patients **because** doctors can check health remotely.  
- **Discuss**: Privacy concerns if sensitive health data leaks — fix with strong security.

**Predictive Analytics** – Outbreak Prediction  
- **Describe**: AI analyses health data to predict potential disease outbreaks.  
- **Explain**: Helps governments prepare **because** resources can be sent to high-risk areas.  
- **Discuss**: Wrong predictions may waste resources — fix by using multiple data sources.

---

#### 5.2 Car Safety

**ML (Supervised Classification)** – Road Surface Detection  
- **Describe**: A model classifies road surfaces (wet, icy, dry) from sensor data.  
- **Explain**: Improves safety **because** braking adjusts to road conditions.  
- **Discuss**: Rare conditions may confuse AI — fix with simulated training data.

**NN (CNN)** – Pedestrian Detection  
- **Describe**: A CNN detects pedestrians in dashcam images to trigger automatic braking.  
- **Explain**: Reduces accidents **because** AI reacts faster than humans.  
- **Discuss**: Poor lighting can cause missed detections — fix with infrared sensors.

**CNN + Image Analysis** – Lane Keeping Assist  
- **Describe**: AI uses cameras to detect lane markings and keep the car centred.  
- **Explain**: Prevents drifting **because** the system gently steers the car back.  
- **Discuss**: Worn or missing road lines may confuse AI — fix with GPS support.

**ML (Supervised)** – Adaptive Cruise Control  
- **Describe**: AI adjusts car speed to keep a safe distance from the vehicle ahead.  
- **Explain**: Prevents rear-end crashes **because** the car automatically brakes and accelerates.  
- **Discuss**: Sudden driver actions may still cause collisions — fix by combining with emergency braking.

**Sensor Fusion + Radar** – Blind Spot Monitoring  
- **Describe**: AI analyses radar sensors to detect cars in blind spots.  
- **Explain**: Increases safety **because** drivers are alerted before lane changes.  
- **Discuss**: False alarms in heavy rain can annoy drivers — fix with multi-sensor checks.

**Driver Monitoring (CNN + Sensors)** – Drowsiness Detection  
- **Describe**: AI analyses steering and facial patterns to detect drowsiness.  
- **Explain**: Reduces crashes **because** it alerts drivers to rest.  
- **Discuss**: False alerts may frustrate drivers — fix with multiple signals (eye + steering).

**Collision Avoidance (AEB)** – Automatic Braking  
- **Describe**: AI detects obstacles and brakes if the driver doesn’t.  
- **Explain**: Saves lives **because** it reacts faster than humans.  
- **Discuss**: System may fail in fog or glare — fix with redundant sensors.

**Predictive Maintenance (ML Regression)** – Vehicle Health  
- **Describe**: AI analyses car sensor data to predict part failures.  
- **Explain**: Prevents breakdowns **because** issues are fixed before they cause accidents.  
- **Discuss**: Over-predicting can waste money — fix with continual model updates.

---

### 6. Sources
- NZQA Assessment Standard PDF: as91898.pdf  
- OMI JSON file: as91898.json  
- Past Exams: 91898-cat-B-2023.pdf  
- Curriculum Resource: CS_Exam_AI_Resource.txt (2025 Content Guide)  
